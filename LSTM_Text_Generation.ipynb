{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Text_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alok13/Machine-Learning/blob/master/LSTM_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hDOjycqwggM",
        "colab_type": "text"
      },
      "source": [
        "**CHARACTER WISE TEXT GENERATION **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPGc4WS6wqvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e2c3a4-d0a0-463d-e9bd-a403b27d80d8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-8fo4T_9IWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "43f86104-3a2e-42f7-c07d-13c2e9b30716"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCKDZjSn9YUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cf4c4bc-36b9-4f50-c299-a8fe72da68fc"
      },
      "source": [
        "text=open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py4qULpZ-Cnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c60674d8-3a03-42a4-a5a6-33a4b3dcb660"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VNzkAlR-F3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PO52i_0-LuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62bceee7-11f2-45d7-c128-b3fc075741b3"
      },
      "source": [
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoTAgzYf-QQx",
        "colab_type": "text"
      },
      "source": [
        "**PROCESS THE TEXT**\n",
        "We need to map strings to a numerical representation. Creating two lookup tables : one mapping characters to numbers and another for numbers to character.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiQfOkWw-OOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {u: i for i,u in enumerate(vocab)}\n",
        "idx2char =np.array(vocab)\n",
        "\n",
        "text_as_int =np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WldjYdtx_pyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "dbd99b94-2415-4c7f-8f00-5834eb6d4293"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-9NlV49Fbbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bdb598e1-fd19-4562-8d61-775f59c39081"
      },
      "source": [
        "print(char2idx)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf47x24eF39z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5f8d1b0f-ba79-41a0-ae47-471aa21458d0"
      },
      "source": [
        "print(idx2char)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
            " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
            " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
            " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r12QmkJwF9Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d1ecbbc-d60c-49db-81b6-cad73609b290"
      },
      "source": [
        "for aa in idx2char:\n",
        "   print('  {:4s}: {:3d},'.format(repr(aa), list(idx2char).index(aa)))\n",
        "   \n",
        "  "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  'H' :  20,\n",
            "  'I' :  21,\n",
            "  'J' :  22,\n",
            "  'K' :  23,\n",
            "  'L' :  24,\n",
            "  'M' :  25,\n",
            "  'N' :  26,\n",
            "  'O' :  27,\n",
            "  'P' :  28,\n",
            "  'Q' :  29,\n",
            "  'R' :  30,\n",
            "  'S' :  31,\n",
            "  'T' :  32,\n",
            "  'U' :  33,\n",
            "  'V' :  34,\n",
            "  'W' :  35,\n",
            "  'X' :  36,\n",
            "  'Y' :  37,\n",
            "  'Z' :  38,\n",
            "  'a' :  39,\n",
            "  'b' :  40,\n",
            "  'c' :  41,\n",
            "  'd' :  42,\n",
            "  'e' :  43,\n",
            "  'f' :  44,\n",
            "  'g' :  45,\n",
            "  'h' :  46,\n",
            "  'i' :  47,\n",
            "  'j' :  48,\n",
            "  'k' :  49,\n",
            "  'l' :  50,\n",
            "  'm' :  51,\n",
            "  'n' :  52,\n",
            "  'o' :  53,\n",
            "  'p' :  54,\n",
            "  'q' :  55,\n",
            "  'r' :  56,\n",
            "  's' :  57,\n",
            "  't' :  58,\n",
            "  'u' :  59,\n",
            "  'v' :  60,\n",
            "  'w' :  61,\n",
            "  'x' :  62,\n",
            "  'y' :  63,\n",
            "  'z' :  64,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt-yXCqF_9GN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "7ac581eb-79b6-4c4c-febf-d1eb90c1159d"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nufLYF7dACgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "29c2037e-366d-4858-86cc-ebf958e2242d"
      },
      "source": [
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W0UtuxpMJe8",
        "colab_type": "text"
      },
      "source": [
        "break the text into chunks of seq_length+1. For example, say seq_length is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grGj1juEMB_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "f75ac472-4760-4d2d-d0a3-bc1670cc3738"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(30):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n",
            "z\n",
            "e\n",
            "n\n",
            ":\n",
            "\n",
            "\n",
            "B\n",
            "e\n",
            "f\n",
            "o\n",
            "r\n",
            "e\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "p\n",
            "r\n",
            "o\n",
            "c\n",
            "e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q_FrXnNMtiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b34a3342-2643-43fb-9b16-80d225c9635d"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7OUo93GNuRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3WVhV9xN4Ei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6a0207d5-56ff-4345-994b-df4777672f41"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci_AJHLqOlqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "9136497c-bdb6-4640-f099-eabba0ee398f"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:10], target_example[:10])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 18 ('F')\n",
            "  expected output: 47 ('i')\n",
            "Step    1\n",
            "  input: 47 ('i')\n",
            "  expected output: 56 ('r')\n",
            "Step    2\n",
            "  input: 56 ('r')\n",
            "  expected output: 57 ('s')\n",
            "Step    3\n",
            "  input: 57 ('s')\n",
            "  expected output: 58 ('t')\n",
            "Step    4\n",
            "  input: 58 ('t')\n",
            "  expected output: 1 (' ')\n",
            "Step    5\n",
            "  input: 1 (' ')\n",
            "  expected output: 15 ('C')\n",
            "Step    6\n",
            "  input: 15 ('C')\n",
            "  expected output: 47 ('i')\n",
            "Step    7\n",
            "  input: 47 ('i')\n",
            "  expected output: 58 ('t')\n",
            "Step    8\n",
            "  input: 58 ('t')\n",
            "  expected output: 47 ('i')\n",
            "Step    9\n",
            "  input: 47 ('i')\n",
            "  expected output: 64 ('z')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYYdQrNwO12i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa1b1463-d280-4d1e-9784-ab7f862f1981"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuAF7ZUyQMmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuFMJaDsQQbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHPBiRL8QVpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =build_model(vocab_size=len(vocab),\n",
        "                   embedding_dim=embedding_dim,\n",
        "                   rnn_units=rnn_units,\n",
        "                   batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRei_r2rRFqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065cc95a-75a3-4b2f-d22a-d7ff6902e9ed"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJEwRtBdRROa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "7832ac72-5daf-45f4-ecb5-14b886d134c7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeVrhwsMSMqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHySM_s5SYhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "559a6c59-e717-4376-a89d-1e6e8dcb0109"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([58, 18, 24,  0, 47, 31, 12, 44, 50, 32, 49, 35, 31, 18,  6, 21,  0,\n",
              "       32, 55, 29, 62, 11, 59, 50, 31, 17, 11, 18, 31,  5, 15, 63, 15, 42,\n",
              "       51, 60,  2, 19, 59, 10, 28, 51,  9, 30, 38, 63, 57, 41, 18, 14, 23,\n",
              "       16,  5, 17,  7, 60, 21, 53, 58, 41, 52, 53,  8, 41, 40, 23, 45, 31,\n",
              "       64, 51, 41, 42, 27,  8, 48, 34, 33,  5, 51, 61,  2, 53,  1,  6, 17,\n",
              "        7, 11,  7, 37, 55, 43, 49, 46, 33, 22, 14, 39, 30,  4, 41])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs3UDQuqSdTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "effdbf2b-c7ea-4690-c14f-fe5bc977cd94"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " \"n whilst\\n'Twixt you there's difference; but the fall of either\\nMakes the survivor heir of all.\\n\\nAUFI\"\n",
            "\n",
            "Next Char Predictions: \n",
            " \"tFL\\niS?flTkWSF,I\\nTqQx;ulSE;FS'CyCdmv!Gu:Pm3RZyscFBKD'E-vIotcno.cbKgSzmcdO.jVU'mw!o ,E-;-YqekhUJBaR&c\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VSjfVVRTWnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f9d071a1-4a34-4a1a-eedd-f413d8054214"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.174924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne-Nsp6_Tcpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ecwOeJKTg08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints_1'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-QI7BhMTkIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W51Wi2qRTmyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab4c203c-00d5-4292-b3a3-d1ab4fa64694"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 2.6560\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 10s 61ms/step - loss: 1.9543\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 11s 61ms/step - loss: 1.6856\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 11s 62ms/step - loss: 1.5385\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 11s 63ms/step - loss: 1.4515\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 11s 63ms/step - loss: 1.3910\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 11s 63ms/step - loss: 1.3454\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 11s 64ms/step - loss: 1.3070\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 11s 65ms/step - loss: 1.2713\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 11s 65ms/step - loss: 1.2382\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 11s 65ms/step - loss: 1.2065\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 11s 66ms/step - loss: 1.1734\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 11s 66ms/step - loss: 1.1414\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 11s 66ms/step - loss: 1.1078\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 11s 66ms/step - loss: 1.0721\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 11s 66ms/step - loss: 1.0379\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 12s 67ms/step - loss: 1.0031\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 11s 67ms/step - loss: 0.9668\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.9318\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 12s 67ms/step - loss: 0.8987\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.8668\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.8379\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.8125\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.7870\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.7668\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.7458\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 12s 67ms/step - loss: 0.7319\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 12s 67ms/step - loss: 0.7168\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 12s 67ms/step - loss: 0.7034\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 0.6927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KitFWp3JU5jO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8fc8f66-ae38-4a01-8398-6f7a4a213b37"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints_1/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvltE3u-U94T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNCf-NxdVBH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "cf72cbdf-e50b-403e-a3f5-cc7112d7f883"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfsYVpSeUjaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHApayCCUpw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "a74e0ab9-1568-4f4c-fe9b-2bbbcbd46413"
      },
      "source": [
        "print(generate_text(model, start_string=u\"ROMEO: \"))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: I have been at Dicharding hell!\n",
            "Dorset, what lives, Tyrand to the crown,\n",
            "Who gave his body to my wife;\n",
            "Lo, here thou didst prove by him when have I with thy\n",
            "bring it to give him again to the body,\n",
            "That shall be together weeping. I would he was bewrancius\n",
            "Which hath his time of eyes. Churber so sweet a prince's day,\n",
            "With love's power. Let such\n",
            "For full of our own desire.\n",
            "\n",
            "CORIOLANUS:\n",
            "Turn these will efus business in the cestary.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Now, if thou love me, that shall become to our laughs,\n",
            "Are too late, or one dead little? What's the cunning turn,\n",
            "For him tyrant banishment,\n",
            "That they our leisure ise out.\n",
            "\n",
            "MERCUTIO:\n",
            "Out of heaven. Prepare to my teeter-hide inquirether.\n",
            "\n",
            "YORK:\n",
            "The cords of Tranio piercing blords.\n",
            "\n",
            "ARCHIDAMUS:\n",
            "Believe me, lords,\n",
            "Be ruled her Sicily proge,\n",
            "Too little gales of honour' both;\n",
            "'Gawnets or old, Scroop,\n",
            "Her father be either by great hands that place else hall, 'go.\n",
            "\n",
            "TRANIO:\n",
            "Such words I did rude as much beggure, so fornt I choose enmitable.\n",
            "\n",
            "HENRY BOLINGBRO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apwHw8fX6XB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "9c401621-b797-4aa5-86de-0a64948cea32"
      },
      "source": [
        "print(generate_text(model, start_string=u\"This is amazing \"))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is amazing array disless.\n",
            "\n",
            "RIVERS:\n",
            "But that's not queen? you are se on the world.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "But thou art true, 'tis for the power of King of\n",
            "The palme-place.\n",
            "\n",
            "ORIOLANUS:\n",
            "Well, sir, I do;\n",
            "I do refer me to your successes.\n",
            "\n",
            "Second Messenger:\n",
            "A worthie thanks; but long have done\n",
            "Great creatures tell me that you pay.\n",
            "\n",
            "POLIXENES:\n",
            "More noble loss!\n",
            "\n",
            "GREMIO:\n",
            "Trempeal to the fire, and prayers, alike:\n",
            "This I can wish to-night,\n",
            "Nor children, content to misis paragon ste with him.\n",
            "\n",
            "Pedartimys,\n",
            "Since at our hands;' it is your tribune.\n",
            "\n",
            "SICINIUS:\n",
            "Go all Pompey? well, I may make you:\n",
            "Confire the clouds,\n",
            "They love it is too good for nd.\n",
            "I told you whose eldertainted to the worst is called for's!\n",
            "\n",
            "PETRUCHIO:\n",
            "The moonsworsel commonway thee! how love she is my love?\n",
            "Prove the oratness reading thus sense too bitter\n",
            "Upon the set of better perisper of my brain.\n",
            "\n",
            "WARWICK:\n",
            "True; Clarence! boy? cannot steal which often\n",
            "With him to pry log as your children;\n",
            "Worthily wrought by any secret midnight-good to our friend?\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}